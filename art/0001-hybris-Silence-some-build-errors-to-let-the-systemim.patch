From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Bj=C3=B6rn=20Bidar?= <theodorstormgrade@gmail.com>
Date: Fri, 3 Jul 2020 22:15:49 +0200
Subject: [PATCH] (hybris) Silence some build errors to let the systemimage
 build
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Previous changes to bionic and the build system removed things that
art depends on. Either remove the parts that create errors or replace
them and insert dummy data to allow the building of the systemimage.

Signed-off-by: Bj√∂rn Bidar <theodorstormgrade@gmail.com>
Change-Id: Ide41188b6263a22c371ec28786bbc1ef1ee62df7
---
 runtime/thread-current-inl.h |  6 +++---
 runtime/thread.cc            | 16 +++++++++++++---
 runtime/thread_list.cc       | 16 ++++++++++++++--
 3 files changed, 30 insertions(+), 8 deletions(-)

diff --git a/runtime/thread-current-inl.h b/runtime/thread-current-inl.h
index d12a45c556..d84b6395f1 100644
--- a/runtime/thread-current-inl.h
+++ b/runtime/thread-current-inl.h
@@ -33,8 +33,8 @@ inline Thread* Thread::Current() {
   if (!is_started_) {
     return nullptr;
   } else {
-#ifdef __BIONIC__
-    void* thread = __get_tls()[TLS_SLOT_ART_THREAD_SELF];
+#ifdef DISABLED_FOR_HYBRIS_SUPPORT
+    void* thread = nullptr; //__get_tls()[TLS_SLOT_ART_THREAD_SELF];
 #else
     Thread* thread = Thread::self_tls_;
 #endif
@@ -44,4 +44,4 @@ inline Thread* Thread::Current() {
 
 }  // namespace art
 
-#endif  // ART_RUNTIME_THREAD_CURRENT_INL_H_
+#endif  // ART_RUNTIME_THREAD_CURRENT_INL_H_
\ No newline at end of file
diff --git a/runtime/thread.cc b/runtime/thread.cc
index 16a5f93be4..595e23ff3a 100644
--- a/runtime/thread.cc
+++ b/runtime/thread.cc
@@ -949,7 +949,7 @@ bool Thread::Init(ThreadList* thread_list, JavaVMExt* java_vm, JNIEnvExt* jni_en
     interpreter::InitInterpreterTls(this);
   }
 
-#ifdef __BIONIC__
+#ifdef DISABLED_FOR_HYBRIS_SUPPORT
   __get_tls()[TLS_SLOT_ART_THREAD_SELF] = this;
 #else
   CHECK_PTHREAD_CALL(pthread_setspecific, (Thread::pthread_key_self_, this), "attach self");
@@ -1468,6 +1468,7 @@ bool Thread::ModifySuspendCountInternal(Thread* self,
 
   tls32_.suspend_count += delta;
   switch (reason) {
+
     case SuspendReason::kForUserCode:
       tls32_.user_code_suspend_count += delta;
       break;
@@ -2163,10 +2164,12 @@ void Thread::DumpJavaStack(std::ostream& os, bool check_suspended, bool dump_loc
   // thread.
   ScopedExceptionStorage ses(Thread::Current());
 
+
   std::unique_ptr<Context> context(Context::Create());
   StackDumpVisitor dumper(os, const_cast<Thread*>(this), context.get(),
                           !tls32_.throwing_OutOfMemoryError, check_suspended, dump_locks);
   dumper.WalkStack();
+
 }
 
 void Thread::DumpStack(std::ostream& os,
@@ -2186,6 +2189,7 @@ void Thread::DumpStack(std::ostream& os,
   if (safe_to_dump || force_dump_stack) {
     // If we're currently in native code, dump that stack before dumping the managed stack.
     if (dump_native_stack && (dump_for_abort || force_dump_stack || ShouldShowNativeStack(this))) {
+
       ArtMethod* method =
           GetCurrentMethod(nullptr,
                            /*check_suspended=*/ !force_dump_stack,
@@ -2206,7 +2210,7 @@ void Thread::ThreadExitCallback(void* arg) {
     LOG(WARNING) << "Native thread exiting without having called DetachCurrentThread (maybe it's "
         "going to use a pthread_key_create destructor?): " << *self;
     CHECK(is_started_);
-#ifdef __BIONIC__
+#ifdef DISABLED_FOR_HYBRIS_SUPPORT
     __get_tls()[TLS_SLOT_ART_THREAD_SELF] = self;
 #else
     CHECK_PTHREAD_CALL(pthread_setspecific, (Thread::pthread_key_self_, self), "reattach self");
@@ -2461,6 +2465,7 @@ void Thread::Destroy() {
   }
 }
 
+
 Thread::~Thread() {
   CHECK(tlsPtr_.class_loader_override == nullptr);
   CHECK(tlsPtr_.jpeer == nullptr);
@@ -2497,6 +2502,7 @@ Thread::~Thread() {
     CleanupCpu();
   }
 
+
   delete tlsPtr_.instrumentation_stack;
   delete tlsPtr_.name;
   delete tlsPtr_.deps_or_stack_trace_sample.stack_trace_sample;
@@ -3655,6 +3661,7 @@ void Thread::QuickDeliverException() {
     }
     if (force_retry_instr) {
       DCHECK(Runtime::Current()->AreNonStandardExitsEnabled());
+
     }
     force_deopt = force_frame_pop || force_retry_instr;
   }
@@ -3785,6 +3792,7 @@ class ReferenceMapVisitor : public StackVisitor {
     VisitDeclaringClass(m);
     DCHECK(m != nullptr);
     size_t num_regs = shadow_frame->NumberOfVRegs();
+
     // handle scope for JNI or References for interpreter.
     for (size_t reg = 0; reg < num_regs; ++reg) {
       mirror::Object* ref = shadow_frame->GetVRegReference(reg);
@@ -4140,6 +4148,7 @@ void Thread::VisitRoots(RootVisitor* visitor) {
   tlsPtr_.jni_env->VisitJniLocalRoots(visitor, RootInfo(kRootJNILocal, thread_id));
   tlsPtr_.jni_env->VisitMonitorRoots(visitor, RootInfo(kRootJNIMonitor, thread_id));
   HandleScopeVisitRoots(visitor, thread_id);
+
   // Visit roots for deoptimization.
   if (tlsPtr_.stacked_shadow_frame_record != nullptr) {
     RootCallbackVisitor visitor_to_callback(visitor, thread_id);
@@ -4327,6 +4336,7 @@ bool Thread::UnprotectStack() {
   return mprotect(pregion, kStackOverflowProtectedSize, PROT_READ|PROT_WRITE) == 0;
 }
 
+
 void Thread::PushVerifier(verifier::MethodVerifier* verifier) {
   verifier->link_ = tlsPtr_.method_verifier;
   tlsPtr_.method_verifier = verifier;
@@ -4496,4 +4506,4 @@ ScopedExceptionStorage::~ScopedExceptionStorage() {
 
 }  // namespace art
 
-#pragma clang diagnostic pop  // -Wconversion
+#pragma clang diagnostic pop  // -Wconversion
\ No newline at end of file
diff --git a/runtime/thread_list.cc b/runtime/thread_list.cc
index 84b7384c46..97a4096aa2 100644
--- a/runtime/thread_list.cc
+++ b/runtime/thread_list.cc
@@ -73,6 +73,7 @@ static constexpr bool kDumpUnattachedThreadNativeStackForSigQuit = true;
 
 ThreadList::ThreadList(uint64_t thread_suspend_timeout_ns)
     : suspend_all_count_(0),
+
       unregistering_count_(0),
       suspend_all_historam_("suspend all histogram", 16, 64),
       long_suspend_(false),
@@ -152,6 +153,7 @@ static void DumpUnattachedThread(std::ostream& os, pid_t tid, bool dump_native_s
   // TODO: No thread safety analysis as DumpState with a null thread won't access fields, should
   // refactor DumpState to avoid skipping analysis.
   Thread::DumpState(os, nullptr, tid);
+
   if (dump_native_stack) {
     DumpNativeStack(os, tid, nullptr, "  native: ");
   }
@@ -338,6 +340,7 @@ size_t ThreadList::RunCheckpoint(Closure* checkpoint_function, Closure* callback
             break;
           } else {
             // The thread is probably suspended, try to make sure that it stays suspended.
+
             if (thread->GetState() == kRunnable) {
               // Spurious fail, try again.
               continue;
@@ -375,6 +378,7 @@ size_t ThreadList::RunCheckpoint(Closure* checkpoint_function, Closure* callback
 
   // Run the checkpoint on the suspended threads.
   for (const auto& thread : suspended_count_modified_threads) {
+
     // We know for sure that the thread is suspended at this point.
     DCHECK(thread->IsSuspended());
     checkpoint_function->Run(thread);
@@ -659,6 +663,7 @@ void ThreadList::SuspendAll(const char* cause, bool long_suspend) {
 }
 
 // Ensures all threads running Java suspend and that those not running Java don't start.
+
 void ThreadList::SuspendAllInternal(Thread* self,
                                     Thread* ignore1,
                                     Thread* ignore2,
@@ -692,6 +697,7 @@ void ThreadList::SuspendAllInternal(Thread* self,
     MutexLock mu2(self, *Locks::thread_suspend_count_lock_);
     // Update global suspend all state for attaching threads.
     ++suspend_all_count_;
+
     pending_threads.store(list_.size() - num_ignored, std::memory_order_relaxed);
     // Increment everybody's suspend count (except those that should be ignored).
     for (const auto& thread : list_) {
@@ -1115,6 +1121,7 @@ Thread* ThreadList::FindThreadByTid(int tid) {
 }
 
 void ThreadList::WaitForOtherNonDaemonThreadsToExit(bool check_no_birth) {
+
   ScopedTrace trace(__PRETTY_FUNCTION__);
   Thread* self = Thread::Current();
   Locks::mutator_lock_->AssertNotHeld(self);
@@ -1122,6 +1129,7 @@ void ThreadList::WaitForOtherNonDaemonThreadsToExit(bool check_no_birth) {
     Locks::runtime_shutdown_lock_->Lock(self);
     if (check_no_birth) {
       // No more threads can be born after we start to shutdown.
+
       CHECK(Runtime::Current()->IsShuttingDownLocked());
       CHECK_EQ(Runtime::Current()->NumberOfThreadsBeingBorn(), 0U);
     } else {
@@ -1180,6 +1188,7 @@ void ThreadList::SuspendAllDaemonThreadsForShutdown() {
   if (daemons_left == 0) {
     // No threads left; safe to shut down.
     return;
+
   }
   // There is not a clean way to shut down if we have daemons left. We have no mechanism for
   // killing them and reclaiming thread stacks. We also have no mechanism for waiting until they
@@ -1212,6 +1221,7 @@ void ThreadList::SuspendAllDaemonThreadsForShutdown() {
     }
     if (found_running) {
       // Sleep briefly before checking again. Max total sleep time is kTimeoutMicroseconds.
+
       usleep(kSleepMicroseconds);
     } else {
       all_suspended = true;
@@ -1269,9 +1279,11 @@ void ThreadList::Register(Thread* self) {
   // SuspendAll requests.
   MutexLock mu(self, *Locks::thread_list_lock_);
   MutexLock mu2(self, *Locks::thread_suspend_count_lock_);
+
   // Modify suspend count in increments of 1 to maintain invariants in ModifySuspendCount. While
   // this isn't particularly efficient the suspend counts are most commonly 0 or 1.
   for (int delta = suspend_all_count_; delta > 0; delta--) {
+
     bool updated = self->ModifySuspendCount(self, +1, nullptr, SuspendReason::kInternal);
     DCHECK(updated);
   }
@@ -1348,7 +1360,7 @@ void ThreadList::Unregister(Thread* self) {
 
   // Clear the TLS data, so that the underlying native thread is recognizably detached.
   // (It may wish to reattach later.)
-#ifdef __BIONIC__
+#ifdef DISABLED_FOR_HYBRIS_SUPPORT
   __get_tls()[TLS_SLOT_ART_THREAD_SELF] = nullptr;
 #else
   CHECK_PTHREAD_CALL(pthread_setspecific, (Thread::pthread_key_self_, nullptr), "detach self");
@@ -1451,4 +1463,4 @@ ScopedSuspendAll::~ScopedSuspendAll() {
   Runtime::Current()->GetThreadList()->ResumeAll();
 }
 
-}  // namespace art
+}  // namespace art
\ No newline at end of file
-- 
2.25.1

